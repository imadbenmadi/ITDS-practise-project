{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e6f8e2",
   "metadata": {},
   "source": [
    "**full Name:** benmadi imed-eddine\n",
    "**Neptun code:** DXU35B\n",
    "**Kaggle notebook:** https://www.kaggle.com/code/imedbenmadi/itds-practise-project\n",
    "**github repostry:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2f19f",
   "metadata": {},
   "source": [
    "# World War II Weather Data Analysis\n",
    "\n",
    "This notebook analyzes historical weather data from World War II to explore weather patterns and build predictive models. The analysis includes data exploration, cleaning, visualization, time series analysis, and machine learning model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894b0b5",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e47a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Geospatial analysis\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "import geopandas as gpd\n",
    "\n",
    "# Machine learning and statistical analysis\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f507d307",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration\n",
    "\n",
    "In this section, we'll load the WWII weather dataset and examine its structure to understand the available features and data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeddd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: You might need to adjust the file path based on where you've stored the dataset\n",
    "try:\n",
    "    # Try to load the data\n",
    "    df = pd.read_csv('wwii_weather_data.csv')\n",
    "    print(\"Data loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"If you haven't downloaded the dataset yet, please obtain it from Kaggle or appropriate source.\")\n",
    "    # Create sample data for demonstration if file not found\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Generate sample dates during WWII (1939-1945)\n",
    "    dates = pd.date_range(start='1939-09-01', end='1945-09-02', freq='D')\n",
    "    \n",
    "    # Creating sample data\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    n_samples = len(dates)\n",
    "    \n",
    "    # Sample locations in Europe\n",
    "    locations = [\n",
    "        ('London', 51.5074, -0.1278),\n",
    "        ('Berlin', 52.5200, 13.4050),\n",
    "        ('Paris', 48.8566, 2.3522),\n",
    "        ('Warsaw', 52.2297, 21.0122),\n",
    "        ('Moscow', 55.7558, 37.6173)\n",
    "    ]\n",
    "    \n",
    "    # Create sample dataframe\n",
    "    sample_data = []\n",
    "    \n",
    "    for date in dates:\n",
    "        for name, lat, lon in locations:\n",
    "            # Generate random weather data with seasonal patterns\n",
    "            month = date.month\n",
    "            seasonal_temp = 15 + 10 * np.sin((month - 1) * np.pi / 6)  # Temperature varies seasonally\n",
    "            \n",
    "            temp_c = seasonal_temp + np.random.normal(0, 3)  # Add noise\n",
    "            pressure_mb = 1013 + np.random.normal(0, 5)  # Normal pressure with noise\n",
    "            humidity_pct = 60 + np.random.normal(0, 15)  # Humidity with noise\n",
    "            wind_speed_kmh = 10 + np.random.exponential(5)  # Wind speed\n",
    "            \n",
    "            # Create weather condition\n",
    "            conditions = ['Clear', 'Cloudy', 'Rain', 'Snow', 'Fog']\n",
    "            probabilities = [0.4, 0.3, 0.15, 0.1, 0.05]\n",
    "            condition = np.random.choice(conditions, p=probabilities)\n",
    "            \n",
    "            # Adjust for winter months\n",
    "            if month in [12, 1, 2]:\n",
    "                temp_c -= 10\n",
    "                if temp_c < 0 and np.random.random() < 0.4:\n",
    "                    condition = 'Snow'\n",
    "            \n",
    "            sample_data.append({\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'time': f\"{np.random.randint(0, 24):02d}:00\",\n",
    "                'location': name,\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                'temperature_celsius': round(temp_c, 1),\n",
    "                'pressure_mb': round(pressure_mb, 1),\n",
    "                'humidity_percent': min(max(0, round(humidity_pct, 1)), 100),\n",
    "                'wind_speed_kmh': round(wind_speed_kmh, 1),\n",
    "                'weather_condition': condition\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957061b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff6b68",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing\n",
    "\n",
    "In this section, we'll clean the dataset by handling missing values, removing duplicates, converting data types, and standardizing measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date and time columns into a single datetime column\n",
    "df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "\n",
    "# Set datetime as index for time series analysis\n",
    "df_ts = df.set_index('datetime').sort_index()\n",
    "\n",
    "# Handle missing values\n",
    "# For numerical columns, we'll use interpolation, which is suitable for time series data\n",
    "numeric_cols = ['temperature_celsius', 'pressure_mb', 'humidity_percent', 'wind_speed_kmh']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Check if column exists and has missing values\n",
    "    if col in df.columns and df[col].isnull().sum() > 0:\n",
    "        # Group by location before interpolating to maintain geographical consistency\n",
    "        df[col] = df.groupby('location')[col].transform(\n",
    "            lambda x: x.interpolate(method='time').ffill().bfill()\n",
    "        )\n",
    "\n",
    "# For categorical data like weather_condition, use most frequent value in the same location\n",
    "if 'weather_condition' in df.columns and df['weather_condition'].isnull().sum() > 0:\n",
    "    df['weather_condition'] = df.groupby('location')['weather_condition'].transform(\n",
    "        lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Unknown')\n",
    "    )\n",
    "\n",
    "# Remove duplicates if any exist\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Check if any missing values remain\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(missing_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14712e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types and standardize units if necessary\n",
    "# Ensure numerical columns are of the right type\n",
    "df_cleaned['temperature_celsius'] = pd.to_numeric(df_cleaned['temperature_celsius'], errors='coerce')\n",
    "df_cleaned['pressure_mb'] = pd.to_numeric(df_cleaned['pressure_mb'], errors='coerce')\n",
    "df_cleaned['humidity_percent'] = pd.to_numeric(df_cleaned['humidity_percent'], errors='coerce')\n",
    "df_cleaned['wind_speed_kmh'] = pd.to_numeric(df_cleaned['wind_speed_kmh'], errors='coerce')\n",
    "\n",
    "# Clamp values to reasonable ranges\n",
    "df_cleaned['humidity_percent'] = df_cleaned['humidity_percent'].clip(0, 100)\n",
    "df_cleaned['pressure_mb'] = df_cleaned['pressure_mb'].clip(900, 1100)  # Reasonable atmospheric pressure range\n",
    "\n",
    "# Add derived datetime components for analysis\n",
    "df_cleaned['year'] = df_cleaned['datetime'].dt.year\n",
    "df_cleaned['month'] = df_cleaned['datetime'].dt.month\n",
    "df_cleaned['day'] = df_cleaned['datetime'].dt.day\n",
    "df_cleaned['hour'] = df_cleaned['datetime'].dt.hour\n",
    "df_cleaned['season'] = df_cleaned['datetime'].dt.month.map({\n",
    "    1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', \n",
    "    5: 'Spring', 6: 'Summer', 7: 'Summer', 8: 'Summer', \n",
    "    9: 'Fall', 10: 'Fall', 11: 'Fall', 12: 'Winter'\n",
    "})\n",
    "\n",
    "# Save the cleaned dataframe for further analysis\n",
    "df = df_cleaned\n",
    "\n",
    "# Display the cleaned data\n",
    "print(f\"Shape of cleaned data: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350bf9c",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "Now that we have cleaned the data, let's explore it through various visualizations and statistical analyses to identify patterns and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a unified figure style for consistency\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 8),\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10\n",
    "})\n",
    "\n",
    "# 1. Distribution of temperature readings\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['temperature_celsius'], kde=True)\n",
    "plt.title('Temperature Distribution')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df, x='season', y='temperature_celsius')\n",
    "plt.title('Temperature by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Weather conditions distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Count plot of weather conditions\n",
    "condition_counts = df['weather_condition'].value_counts()\n",
    "sns.barplot(x=condition_counts.index, y=condition_counts.values)\n",
    "plt.title('Distribution of Weather Conditions')\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Weather conditions by season\n",
    "plt.figure(figsize=(14, 8))\n",
    "season_condition = pd.crosstab(df['season'], df['weather_condition'], normalize='index') * 100\n",
    "season_condition.plot(kind='bar', stacked=True, colormap='viridis')\n",
    "plt.title('Weather Conditions by Season (%)')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(title='Weather Condition', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22972291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Time series plots for average temperature by location\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Group by date and location, then calculate mean temperature\n",
    "avg_temp_by_date_loc = df.groupby(['date', 'location'])['temperature_celsius'].mean().reset_index()\n",
    "avg_temp_by_date_loc['date'] = pd.to_datetime(avg_temp_by_date_loc['date'])\n",
    "\n",
    "# Plot time series for each location\n",
    "for location in df['location'].unique():\n",
    "    location_data = avg_temp_by_date_loc[avg_temp_by_date_loc['location'] == location]\n",
    "    plt.plot(location_data['date'], location_data['temperature_celsius'], label=location, alpha=0.7)\n",
    "\n",
    "plt.title('Average Daily Temperature by Location')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Temperature (°C)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add vertical lines for significant WWII events\n",
    "events = [\n",
    "    ('1939-09-01', 'War Begins'),\n",
    "    ('1941-06-22', 'Operation Barbarossa'),\n",
    "    ('1941-12-07', 'Pearl Harbor'),\n",
    "    ('1942-11-08', 'Operation Torch'),\n",
    "    ('1944-06-06', 'D-Day'),\n",
    "    ('1945-05-08', 'VE Day'),\n",
    "    ('1945-09-02', 'VJ Day')\n",
    "]\n",
    "\n",
    "for date, label in events:\n",
    "    plt.axvline(x=pd.to_datetime(date), color='red', linestyle='--', alpha=0.5)\n",
    "    plt.text(pd.to_datetime(date), plt.ylim()[1], label, \n",
    "             horizontalalignment='center', verticalalignment='bottom', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e00382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Pressure and humidity analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Pressure distribution\n",
    "sns.histplot(df['pressure_mb'], kde=True, ax=axes[0])\n",
    "axes[0].set_title('Pressure Distribution')\n",
    "axes[0].set_xlabel('Pressure (mb)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Humidity distribution\n",
    "sns.histplot(df['humidity_percent'], kde=True, ax=axes[1])\n",
    "axes[1].set_title('Humidity Distribution')\n",
    "axes[1].set_xlabel('Humidity (%)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relationship between temperature, pressure, and humidity\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(df['temperature_celsius'], df['pressure_mb'], \n",
    "                     c=df['humidity_percent'], cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(scatter, label='Humidity (%)')\n",
    "plt.title('Relationship between Temperature, Pressure, and Humidity')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Pressure (mb)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00525e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Wind speed analysis\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['wind_speed_kmh'], kde=True, bins=30)\n",
    "plt.title('Wind Speed Distribution')\n",
    "plt.xlabel('Wind Speed (km/h)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df, x='season', y='wind_speed_kmh')\n",
    "plt.title('Wind Speed by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Wind Speed (km/h)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wind speed vs. weather condition\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='weather_condition', y='wind_speed_kmh')\n",
    "plt.title('Wind Speed by Weather Condition')\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Wind Speed (km/h)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03a54a",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "In this section, we'll create derived features to enhance our analysis and prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe for feature engineering\n",
    "df_featured = df.copy()\n",
    "\n",
    "# 1. Temperature changes (daily delta)\n",
    "daily_temp = df.groupby(['location', 'date'])['temperature_celsius'].agg(['mean', 'min', 'max']).reset_index()\n",
    "daily_temp['temp_range'] = daily_temp['max'] - daily_temp['min']\n",
    "\n",
    "# Merge back to original dataframe\n",
    "df_featured = pd.merge(df_featured, \n",
    "                       daily_temp[['location', 'date', 'temp_range']], \n",
    "                       on=['location', 'date'], \n",
    "                       how='left')\n",
    "\n",
    "# 2. Pressure tendency (rising/falling)\n",
    "# First, sort by location and datetime\n",
    "df_featured = df_featured.sort_values(['location', 'datetime'])\n",
    "\n",
    "# Calculate pressure change from previous observation (by location)\n",
    "df_featured['pressure_change'] = df_featured.groupby('location')['pressure_mb'].diff()\n",
    "\n",
    "# Create categorical feature for pressure tendency\n",
    "df_featured['pressure_tendency'] = pd.cut(\n",
    "    df_featured['pressure_change'], \n",
    "    bins=[-float('inf'), -1, 1, float('inf')],\n",
    "    labels=['Falling', 'Steady', 'Rising']\n",
    ")\n",
    "\n",
    "# 3. Extreme weather indicator\n",
    "df_featured['extreme_temp'] = (\n",
    "    (df_featured['temperature_celsius'] > df_featured.groupby('location')['temperature_celsius'].transform('mean') + 2 * df_featured.groupby('location')['temperature_celsius'].transform('std')) | \n",
    "    (df_featured['temperature_celsius'] < df_featured.groupby('location')['temperature_celsius'].transform('mean') - 2 * df_featured.groupby('location')['temperature_celsius'].transform('std'))\n",
    ")\n",
    "\n",
    "# 4. Dew Point (estimate)\n",
    "# Using Magnus formula for approximation\n",
    "df_featured['dew_point'] = df_featured['temperature_celsius'] - ((100 - df_featured['humidity_percent']) / 5)\n",
    "\n",
    "# 5. Heat Index (simplified version)\n",
    "# Only calculated for temperatures above 20°C\n",
    "mask = df_featured['temperature_celsius'] > 20\n",
    "df_featured.loc[mask, 'heat_index'] = (\n",
    "    df_featured.loc[mask, 'temperature_celsius'] + \n",
    "    0.05 * df_featured.loc[mask, 'humidity_percent'] *\n",
    "    (df_featured.loc[mask, 'temperature_celsius'] - 20)\n",
    ")\n",
    "df_featured.loc[~mask, 'heat_index'] = df_featured.loc[~mask, 'temperature_celsius']\n",
    "\n",
    "# 6. Season-normalized temperature (z-score within each season)\n",
    "df_featured['season_norm_temp'] = df_featured.groupby(['location', 'season'])['temperature_celsius'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std() if len(x) > 1 and x.std() > 0 else 0\n",
    ")\n",
    "\n",
    "# 7. Weather severity index (simplified)\n",
    "# Map weather conditions to severity scores\n",
    "severity_map = {\n",
    "    'Clear': 1,\n",
    "    'Cloudy': 2,\n",
    "    'Fog': 3,\n",
    "    'Rain': 4,\n",
    "    'Snow': 5\n",
    "}\n",
    "\n",
    "# Apply mapping if weather_condition column contains these values\n",
    "if set(severity_map.keys()).intersection(set(df_featured['weather_condition'].unique())):\n",
    "    df_featured['weather_severity'] = df_featured['weather_condition'].map(severity_map).fillna(1)\n",
    "else:\n",
    "    # Create a simple severity based on wind speed and temperature extremes as fallback\n",
    "    df_featured['weather_severity'] = 1\n",
    "    df_featured.loc[df_featured['wind_speed_kmh'] > 20, 'weather_severity'] += 1\n",
    "    df_featured.loc[df_featured['wind_speed_kmh'] > 40, 'weather_severity'] += 1\n",
    "    df_featured.loc[df_featured['extreme_temp'], 'weather_severity'] += 1\n",
    "\n",
    "# Display the newly engineered features\n",
    "print(\"Feature engineering complete. New columns added:\")\n",
    "new_columns = ['temp_range', 'pressure_change', 'pressure_tendency', 'extreme_temp',\n",
    "              'dew_point', 'heat_index', 'season_norm_temp', 'weather_severity']\n",
    "df_featured[new_columns].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the new features\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Temperature Range by Season\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(data=df_featured, x='season', y='temp_range')\n",
    "plt.title('Temperature Range by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Temperature Range (°C)')\n",
    "\n",
    "# Plot 2: Dew Point vs. Temperature\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(df_featured['temperature_celsius'], df_featured['dew_point'], alpha=0.5)\n",
    "plt.title('Dew Point vs. Temperature')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Dew Point (°C)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot 3: Pressure Tendency Distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "pressure_tendency_counts = df_featured['pressure_tendency'].value_counts()\n",
    "sns.barplot(x=pressure_tendency_counts.index, y=pressure_tendency_counts.values)\n",
    "plt.title('Distribution of Pressure Tendencies')\n",
    "plt.xlabel('Pressure Tendency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Plot 4: Weather Severity by Location\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(data=df_featured, x='location', y='weather_severity')\n",
    "plt.title('Weather Severity by Location')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Weather Severity Index')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4295f6b",
   "metadata": {},
   "source": [
    "## 6. Time Series Analysis\n",
    "\n",
    "Let's analyze weather patterns over time and decompose time series to identify trends and seasonality in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single location for time series analysis\n",
    "# For demonstration, we'll use the first location in our dataset\n",
    "location_focus = df['location'].unique()[0]\n",
    "print(f\"Focusing on location: {location_focus}\")\n",
    "\n",
    "# Create a time series dataset for selected location\n",
    "ts_data = df[df['location'] == location_focus].set_index('datetime').sort_index()\n",
    "\n",
    "# Resample to daily average temperature\n",
    "daily_avg_temp = ts_data['temperature_celsius'].resample('D').mean()\n",
    "\n",
    "# Handling missing values in the resampled data\n",
    "daily_avg_temp = daily_avg_temp.interpolate()\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "daily_avg_temp.plot()\n",
    "plt.title(f'Daily Average Temperature at {location_focus}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Check stationarity with ADF test\n",
    "result = adfuller(daily_avg_temp.dropna())\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print(f'   {key}: {value}')\n",
    "\n",
    "# Interpret results\n",
    "if result[1] <= 0.05:\n",
    "    print(\"The time series is stationary (reject H0)\")\n",
    "else:\n",
    "    print(\"The time series is non-stationary (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Decomposition\n",
    "# For decomposition, we need a time series without missing values\n",
    "decomposition = seasonal_decompose(daily_avg_temp.dropna(), model='additive', period=365)\n",
    "\n",
    "# Plot decomposition\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(decomposition.observed)\n",
    "plt.title('Observed')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(decomposition.trend)\n",
    "plt.title('Trend')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(decomposition.seasonal)\n",
    "plt.title('Seasonal')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(decomposition.resid)\n",
    "plt.title('Residual')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d141d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots for understanding autocorrelation patterns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ACF plot\n",
    "plot_acf(daily_avg_temp.dropna(), ax=axes[0], lags=30)\n",
    "axes[0].set_title('Autocorrelation Function (ACF)')\n",
    "\n",
    "# PACF plot\n",
    "plot_pacf(daily_avg_temp.dropna(), ax=axes[1], lags=30)\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple weather variables together for comparative time series analysis\n",
    "# Select a subset of dates for better visualization\n",
    "date_start = pd.to_datetime('1944-01-01')\n",
    "date_end = pd.to_datetime('1944-06-30')\n",
    "\n",
    "# Filter the data for the selected date range\n",
    "ts_subset = ts_data.loc[date_start:date_end]\n",
    "\n",
    "# Resampling to daily averages for multiple variables\n",
    "daily_avg = ts_subset.resample('D').agg({\n",
    "    'temperature_celsius': 'mean',\n",
    "    'pressure_mb': 'mean',\n",
    "    'humidity_percent': 'mean',\n",
    "    'wind_speed_kmh': 'mean'\n",
    "}).dropna()\n",
    "\n",
    "# Normalize the data for comparison on same scale\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = pd.DataFrame(\n",
    "    scaler.fit_transform(daily_avg),\n",
    "    columns=daily_avg.columns,\n",
    "    index=daily_avg.index\n",
    ")\n",
    "\n",
    "# Plot the normalized time series\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in normalized_data.columns:\n",
    "    plt.plot(normalized_data.index, normalized_data[column], label=column)\n",
    "\n",
    "plt.title(f'Normalized Weather Variables at {location_focus} (Jan-Jun 1944)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f5b6e",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "Let's investigate relationships between different weather variables and identify significant dependencies in weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe3179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant numerical columns for correlation analysis\n",
    "corr_columns = ['temperature_celsius', 'pressure_mb', 'humidity_percent', 'wind_speed_kmh', \n",
    "                'dew_point', 'heat_index', 'temp_range', 'pressure_change', 'weather_severity']\n",
    "corr_df = df_featured[corr_columns].copy()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = corr_df.corr().round(2)\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(correlation_matrix, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "            annot=True, fmt='.2f', square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('Correlation Heatmap of Weather Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate correlation patterns by season\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "for i, season in enumerate(['Winter', 'Spring', 'Summer', 'Fall'], 1):\n",
    "    # Filter data by season\n",
    "    season_data = df_featured[df_featured['season'] == season][corr_columns].copy()\n",
    "    \n",
    "    # Calculate correlation matrix for this season\n",
    "    season_corr = season_data.corr().round(2)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.heatmap(season_corr, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "                annot=True, fmt='.2f', square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "    plt.title(f'Correlation Matrix - {season}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f705453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot matrix for key variables\n",
    "subset_vars = ['temperature_celsius', 'pressure_mb', 'humidity_percent', 'wind_speed_kmh']\n",
    "sns.pairplot(df_featured[subset_vars], diag_kind='kde', height=2.5)\n",
    "plt.suptitle('Pairwise Relationships Between Key Weather Variables', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a95fe4",
   "metadata": {},
   "source": [
    "## 8. Geospatial Visualization\n",
    "\n",
    "Now let's visualize weather data geographically to identify spatial patterns and regional variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map centered on Europe\n",
    "map_center = [50.0, 10.0]  # Approximate center of Europe\n",
    "europe_map = folium.Map(location=map_center, zoom_start=4, tiles='CartoDB positron')\n",
    "\n",
    "# Function to calculate average values for a specific date\n",
    "def get_data_for_date(selected_date):\n",
    "    date_data = df_featured[df_featured['date'] == selected_date].copy()\n",
    "    \n",
    "    if len(date_data) == 0:\n",
    "        print(f\"No data available for {selected_date}\")\n",
    "        return None\n",
    "    \n",
    "    # Group by location and calculate averages\n",
    "    location_avg = date_data.groupby(['location', 'latitude', 'longitude']).agg({\n",
    "        'temperature_celsius': 'mean',\n",
    "        'pressure_mb': 'mean',\n",
    "        'humidity_percent': 'mean',\n",
    "        'wind_speed_kmh': 'mean',\n",
    "        'weather_condition': lambda x: x.mode()[0] if not x.mode().empty else 'Unknown'\n",
    "    }).reset_index()\n",
    "    \n",
    "    return location_avg\n",
    "\n",
    "# Select a specific date for visualization\n",
    "selected_date = df_featured['date'].iloc[len(df_featured) // 2]  # Choose a middle date\n",
    "print(f\"Visualizing weather for date: {selected_date}\")\n",
    "\n",
    "date_data = get_data_for_date(selected_date)\n",
    "\n",
    "if date_data is not None:\n",
    "    # Create a marker cluster group\n",
    "    marker_cluster = MarkerCluster().add_to(europe_map)\n",
    "    \n",
    "    # Add markers for each location with weather information\n",
    "    for idx, row in date_data.iterrows():\n",
    "        # Create marker popup with weather information\n",
    "        popup_html = f\"\"\"\n",
    "        <b>{row['location']}</b><br>\n",
    "        Temperature: {row['temperature_celsius']:.1f}°C<br>\n",
    "        Pressure: {row['pressure_mb']:.1f} mb<br>\n",
    "        Humidity: {row['humidity_percent']:.1f}%<br>\n",
    "        Wind Speed: {row['wind_speed_kmh']:.1f} km/h<br>\n",
    "        Condition: {row['weather_condition']}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Color based on temperature\n",
    "        if row['temperature_celsius'] < 0:\n",
    "            color = 'blue'\n",
    "        elif row['temperature_celsius'] < 10:\n",
    "            color = 'lightblue'\n",
    "        elif row['temperature_celsius'] < 20:\n",
    "            color = 'green'\n",
    "        elif row['temperature_celsius'] < 30:\n",
    "            color = 'orange'\n",
    "        else:\n",
    "            color = 'red'\n",
    "            \n",
    "        # Create circle marker\n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=10,\n",
    "            popup=folium.Popup(popup_html, max_width=300),\n",
    "            fill=True,\n",
    "            color=color,\n",
    "            fill_opacity=0.7,\n",
    "            tooltip=f\"{row['location']}: {row['temperature_celsius']:.1f}°C\"\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    # Add a title to the map\n",
    "    title_html = f'''\n",
    "        <h3 align=\"center\" style=\"font-size:16px\"><b>Weather Conditions on {selected_date}</b></h3>\n",
    "    '''\n",
    "    europe_map.get_root().html.add_child(folium.Element(title_html))\n",
    "    \n",
    "    # Display the map\n",
    "    europe_map\n",
    "else:\n",
    "    print(\"No data available for visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c984f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temperature heatmap\n",
    "# This demonstrates how temperature varies across different locations\n",
    "\n",
    "# Get average temperatures for all locations\n",
    "avg_temps = df_featured.groupby(['location', 'latitude', 'longitude'])['temperature_celsius'].mean().reset_index()\n",
    "\n",
    "# Create a base map\n",
    "temp_heatmap = folium.Map(location=map_center, zoom_start=4, tiles='CartoDB positron')\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heat_data = [[row['latitude'], row['longitude'], row['temperature_celsius']] for idx, row in avg_temps.iterrows()]\n",
    "\n",
    "# Add heatmap layer\n",
    "HeatMap(heat_data, radius=15, max_zoom=13, blur=10, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 1: 'red'}).add_to(temp_heatmap)\n",
    "\n",
    "# Add markers for reference\n",
    "for idx, row in avg_temps.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        popup=f\"{row['location']}: {row['temperature_celsius']:.1f}°C\",\n",
    "        color='white',\n",
    "        fill=True,\n",
    "        fill_color='black',\n",
    "        fill_opacity=0.7\n",
    "    ).add_to(temp_heatmap)\n",
    "\n",
    "# Add title\n",
    "title_html = '''\n",
    "    <h3 align=\"center\" style=\"font-size:16px\"><b>Average Temperature Heatmap</b></h3>\n",
    "'''\n",
    "temp_heatmap.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Display the heatmap\n",
    "temp_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2991a",
   "metadata": {},
   "source": [
    "## 9. Weather Pattern Classification\n",
    "\n",
    "In this section, we'll implement clustering algorithms to identify distinct weather patterns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae87dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "# We'll use key weather variables and standardize them\n",
    "\n",
    "# Select features for clustering\n",
    "cluster_features = ['temperature_celsius', 'pressure_mb', 'humidity_percent', 'wind_speed_kmh']\n",
    "cluster_data = df_featured[cluster_features].copy()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(cluster_data)\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "wcss = []  # Within-cluster sum of squares\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(scaled_data)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='-')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8965406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the elbow curve, select an appropriate number of clusters\n",
    "n_clusters = 4  # This should be adjusted based on your actual elbow curve\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "df_featured['weather_cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Get cluster centers and transform back to original scale\n",
    "cluster_centers = pd.DataFrame(\n",
    "    scaler.inverse_transform(kmeans.cluster_centers_),\n",
    "    columns=cluster_features\n",
    ")\n",
    "\n",
    "# Display cluster centers\n",
    "print(\"Cluster Centers:\")\n",
    "print(cluster_centers.round(2))\n",
    "\n",
    "# Visualize the clusters in 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pca_df['Cluster'] = df_featured['weather_cluster']\n",
    "\n",
    "# Create a scatter plot colored by cluster\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='viridis', s=50, alpha=0.7)\n",
    "plt.title('Weather Clusters Visualization (PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Weather Pattern')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the characteristics of each cluster\n",
    "cluster_analysis = df_featured.groupby('weather_cluster').agg({\n",
    "    'temperature_celsius': 'mean',\n",
    "    'pressure_mb': 'mean',\n",
    "    'humidity_percent': 'mean',\n",
    "    'wind_speed_kmh': 'mean',\n",
    "    'dew_point': 'mean',\n",
    "    'heat_index': 'mean',\n",
    "    'weather_severity': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Cluster Characteristics:\")\n",
    "display(cluster_analysis)\n",
    "\n",
    "# Distribution of weather conditions within each cluster\n",
    "weather_by_cluster = pd.crosstab(\n",
    "    df_featured['weather_cluster'], \n",
    "    df_featured['weather_condition'], \n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nWeather Conditions by Cluster (%):\")\n",
    "display(weather_by_cluster.round(1))\n",
    "\n",
    "# Visualize distributions for each feature by cluster\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for i, feature in enumerate(cluster_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x='weather_cluster', y=feature, data=df_featured)\n",
    "    plt.title(f'{feature} by Weather Pattern Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create descriptive labels for each cluster\n",
    "cluster_descriptions = {\n",
    "    0: \"Undefined\",  # This will be updated based on analysis\n",
    "    1: \"Undefined\",\n",
    "    2: \"Undefined\",\n",
    "    3: \"Undefined\"\n",
    "}\n",
    "\n",
    "# Example: Update with meaningful labels based on the cluster analysis results\n",
    "# This should be updated based on your actual cluster characteristics\n",
    "for cluster in range(n_clusters):\n",
    "    if cluster_analysis.loc[cluster, 'temperature_celsius'] > 20:\n",
    "        prefix = \"Warm\"\n",
    "    elif cluster_analysis.loc[cluster, 'temperature_celsius'] < 5:\n",
    "        prefix = \"Cold\"\n",
    "    else:\n",
    "        prefix = \"Mild\"\n",
    "        \n",
    "    if cluster_analysis.loc[cluster, 'humidity_percent'] > 70:\n",
    "        humidity = \"Humid\"\n",
    "    else:\n",
    "        humidity = \"Dry\"\n",
    "        \n",
    "    if cluster_analysis.loc[cluster, 'wind_speed_kmh'] > 15:\n",
    "        wind = \"Windy\"\n",
    "    else:\n",
    "        wind = \"Calm\"\n",
    "        \n",
    "    cluster_descriptions[cluster] = f\"{prefix}, {humidity}, {wind}\"\n",
    "\n",
    "# Add descriptive labels to the dataframe\n",
    "df_featured['weather_pattern'] = df_featured['weather_cluster'].map(cluster_descriptions)\n",
    "\n",
    "# Show the distribution of weather patterns\n",
    "pattern_distribution = df_featured['weather_pattern'].value_counts().reset_index()\n",
    "pattern_distribution.columns = ['Weather Pattern', 'Count']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Weather Pattern', y='Count', data=pattern_distribution)\n",
    "plt.title('Distribution of Identified Weather Patterns')\n",
    "plt.xlabel('Weather Pattern')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48292ebd",
   "metadata": {},
   "source": [
    "## 10. Predictive Modeling\n",
    "\n",
    "In this section, we'll build and evaluate machine learning models to predict weather conditions based on historical patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for predictive modeling\n",
    "# We'll predict next-day temperature based on current weather conditions\n",
    "\n",
    "# Create lagged features\n",
    "model_data = df_featured.copy()\n",
    "\n",
    "# Group by location and sort by datetime\n",
    "model_data = model_data.sort_values(['location', 'datetime'])\n",
    "\n",
    "# Create target variable: next-day temperature\n",
    "model_data['next_day_temp'] = model_data.groupby('location')['temperature_celsius'].shift(-1)\n",
    "\n",
    "# Create lags of 1, 2, and 3 days\n",
    "for lag in range(1, 4):\n",
    "    model_data[f'temp_lag_{lag}'] = model_data.groupby('location')['temperature_celsius'].shift(lag)\n",
    "    model_data[f'pressure_lag_{lag}'] = model_data.groupby('location')['pressure_mb'].shift(lag)\n",
    "    model_data[f'humidity_lag_{lag}'] = model_data.groupby('location')['humidity_percent'].shift(lag)\n",
    "    model_data[f'wind_lag_{lag}'] = model_data.groupby('location')['wind_speed_kmh'].shift(lag)\n",
    "\n",
    "# Drop rows with NaN values created by the shifts\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "# Select features for the model\n",
    "model_features = [\n",
    "    'temperature_celsius', 'pressure_mb', 'humidity_percent', 'wind_speed_kmh',\n",
    "    'temp_lag_1', 'temp_lag_2', 'temp_lag_3',\n",
    "    'pressure_lag_1', 'pressure_lag_2', 'pressure_lag_3',\n",
    "    'humidity_lag_1', 'humidity_lag_2', 'humidity_lag_3',\n",
    "    'wind_lag_1', 'wind_lag_2', 'wind_lag_3',\n",
    "    'month', 'season_norm_temp', 'temp_range'\n",
    "]\n",
    "\n",
    "# Prepare X and y\n",
    "X = model_data[model_features]\n",
    "y = model_data['next_day_temp']\n",
    "\n",
    "# Add categorical features using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X, columns=['month'], drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d31f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Display results\n",
    "print(\"Random Forest Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_rf:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf:.4f}\")\n",
    "print(f\"R² Score: {r2_rf:.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Top 15 Most Important Features for Temperature Prediction')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2abfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a Gradient Boosting Regressor for comparison\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "rmse_gb = np.sqrt(mse_gb)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Display results\n",
    "print(\"Gradient Boosting Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_gb:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_gb:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_gb:.4f}\")\n",
    "print(f\"R² Score: {r2_gb:.4f}\")\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred_gb, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Gradient Boosting: Predicted vs Actual Temperature')\n",
    "plt.xlabel('Actual Temperature (°C)')\n",
    "plt.ylabel('Predicted Temperature (°C)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate prediction errors\n",
    "errors = y_test - y_pred_gb\n",
    "\n",
    "# Plot error distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(errors, kde=True)\n",
    "plt.title('Prediction Error Distribution')\n",
    "plt.xlabel('Prediction Error (°C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=0, color='r', linestyle='-')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Compare models\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Gradient Boosting'],\n",
    "    'RMSE': [rmse_rf, rmse_gb],\n",
    "    'MAE': [mae_rf, mae_gb],\n",
    "    'R²': [r2_rf, r2_gb]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "display(models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df217de3",
   "metadata": {},
   "source": [
    "## 11. User Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf607815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive UI for model testing and prediction\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "\n",
    "import calendar\n",
    "\n",
    "\n",
    "# Create widget components\n",
    "location_dropdown = widgets.Dropdown(\n",
    "    options=df['location'].unique(),\n",
    "    value=df['location'].unique()[0],\n",
    "    description='Location:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "input_method = widgets.RadioButtons(\n",
    "    options=['Use random data', 'Enter manual data'],\n",
    "    description='Input method:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create input widgets for manual data entry\n",
    "temp_input = widgets.FloatSlider(\n",
    "    value=15.0,\n",
    "    min=-30.0,\n",
    "    max=40.0,\n",
    "    step=0.5,\n",
    "    description='Temperature (°C):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "pressure_input = widgets.FloatSlider(\n",
    "    value=1013.0,\n",
    "    min=980.0,\n",
    "    max=1040.0,\n",
    "    step=0.5,\n",
    "    description='Pressure (mb):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "humidity_input = widgets.FloatSlider(\n",
    "    value=65.0,\n",
    "    min=0.0,\n",
    "    max=100.0,\n",
    "    step=1.0,\n",
    "    description='Humidity (%):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "wind_input = widgets.FloatSlider(\n",
    "    value=10.0,\n",
    "    min=0.0,\n",
    "    max=50.0,\n",
    "    step=0.5,\n",
    "    description='Wind Speed (km/h):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "month_input = widgets.Dropdown(\n",
    "    options=[(calendar.month_name[i], i) for i in range(1, 13)],\n",
    "    value=1,\n",
    "    description='Month:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "predict_button = widgets.Button(\n",
    "    description='Predict Next-Day Temperature',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Function to handle prediction\n",
    "def on_predict_button_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        print(\"Processing prediction...\")\n",
    "        \n",
    "        try:\n",
    "            # Check which input method was selected\n",
    "            if input_method.value == 'Use random data':\n",
    "                # Get random sample from existing data for the selected location\n",
    "                location_data = df[df['location'] == location_dropdown.value]\n",
    "                if len(location_data) > 0:\n",
    "                    random_idx = np.random.choice(location_data.index)\n",
    "                    random_sample = location_data.loc[random_idx]\n",
    "                    \n",
    "                    # Display the selected random data\n",
    "                    print(f\"\\n🔍 Using random data from {location_dropdown.value}:\")\n",
    "                    print(f\"  • Date: {random_sample['date']}\")\n",
    "                    print(f\"  • Temperature: {random_sample['temperature_celsius']:.1f}°C\")\n",
    "                    print(f\"  • Pressure: {random_sample['pressure_mb']:.1f} mb\")\n",
    "                    print(f\"  • Humidity: {random_sample['humidity_percent']:.1f}%\")\n",
    "                    print(f\"  • Wind Speed: {random_sample['wind_speed_kmh']:.1f} km/h\")\n",
    "                    \n",
    "                    # Create feature vector for prediction\n",
    "                    # We'll need to handle all the features the model expects\n",
    "                    # For demonstration, we're filling in with sample data and averages\n",
    "                    \n",
    "                    X_pred = pd.DataFrame({\n",
    "                        'temperature_celsius': [random_sample['temperature_celsius']],\n",
    "                        'pressure_mb': [random_sample['pressure_mb']],\n",
    "                        'humidity_percent': [random_sample['humidity_percent']],\n",
    "                        'wind_speed_kmh': [random_sample['wind_speed_kmh']],\n",
    "                        'temp_lag_1': [random_sample['temperature_celsius']],\n",
    "                        'temp_lag_2': [location_data['temperature_celsius'].mean()],\n",
    "                        'temp_lag_3': [location_data['temperature_celsius'].mean()],\n",
    "                        'pressure_lag_1': [random_sample['pressure_mb']],\n",
    "                        'pressure_lag_2': [location_data['pressure_mb'].mean()],\n",
    "                        'pressure_lag_3': [location_data['pressure_mb'].mean()],\n",
    "                        'humidity_lag_1': [random_sample['humidity_percent']],\n",
    "                        'humidity_lag_2': [location_data['humidity_percent'].mean()],\n",
    "                        'humidity_lag_3': [location_data['humidity_percent'].mean()],\n",
    "                        'wind_lag_1': [random_sample['wind_speed_kmh']],\n",
    "                        'wind_lag_2': [location_data['wind_speed_kmh'].mean()],\n",
    "                        'wind_lag_3': [location_data['wind_speed_kmh'].mean()],\n",
    "                        'month': [random_sample['month']],\n",
    "                        'season_norm_temp': [0.0],  # Default value\n",
    "                        'temp_range': [10.0]  # Default value\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"No data available for {location_dropdown.value}\")\n",
    "                    return\n",
    "                \n",
    "            else:  # Manual data entry\n",
    "                # Create feature vector from manual inputs\n",
    "                X_pred = pd.DataFrame({\n",
    "                    'temperature_celsius': [temp_input.value],\n",
    "                    'pressure_mb': [pressure_input.value],\n",
    "                    'humidity_percent': [humidity_input.value],\n",
    "                    'wind_speed_kmh': [wind_input.value],\n",
    "                    'temp_lag_1': [temp_input.value],  # Using current temp as lag 1\n",
    "                    'temp_lag_2': [temp_input.value],  # Using current temp as lag 2\n",
    "                    'temp_lag_3': [temp_input.value],  # Using current temp as lag 3\n",
    "                    'pressure_lag_1': [pressure_input.value],\n",
    "                    'pressure_lag_2': [pressure_input.value],\n",
    "                    'pressure_lag_3': [pressure_input.value],\n",
    "                    'humidity_lag_1': [humidity_input.value],\n",
    "                    'humidity_lag_2': [humidity_input.value],\n",
    "                    'humidity_lag_3': [humidity_input.value],\n",
    "                    'wind_lag_1': [wind_input.value],\n",
    "                    'wind_lag_2': [wind_input.value],\n",
    "                    'wind_lag_3': [wind_input.value],\n",
    "                    'month': [month_input.value],\n",
    "                    'season_norm_temp': [0.0],  # Default value\n",
    "                    'temp_range': [10.0]  # Default value\n",
    "                })\n",
    "                \n",
    "                print(f\"\\n🔍 Using manually entered data for {location_dropdown.value}:\")\n",
    "                print(f\"  • Temperature: {temp_input.value:.1f}°C\")\n",
    "                print(f\"  • Pressure: {pressure_input.value:.1f} mb\")\n",
    "                print(f\"  • Humidity: {humidity_input.value:.1f}%\")\n",
    "                print(f\"  • Wind Speed: {wind_input.value:.1f} km/h\")\n",
    "                print(f\"  • Month: {month_input.label}\")\n",
    "            \n",
    "            # One-hot encode the month variable to match the training data\n",
    "            # Create month columns (matching the training data)\n",
    "            for i in range(2, 13):  # Assuming month_1 is dropped as reference\n",
    "                col_name = f'month_{i}'\n",
    "                X_pred[col_name] = 1 if X_pred['month'].values[0] == i else 0\n",
    "            \n",
    "            # Drop the original 'month' column\n",
    "            X_pred = X_pred.drop(columns=['month'])\n",
    "            \n",
    "            # Add any missing columns from training data (with zeros)\n",
    "            for col in X_train.columns:\n",
    "                if col not in X_pred.columns:\n",
    "                    X_pred[col] = 0\n",
    "            \n",
    "            # Ensure columns are in the same order as training data\n",
    "            X_pred = X_pred[X_train.columns]\n",
    "            \n",
    "            # Make predictions with both models\n",
    "            rf_prediction = rf_model.predict(X_pred)[0]\n",
    "            gb_prediction = gb_model.predict(X_pred)[0]\n",
    "            \n",
    "            # Display results\n",
    "            print(\"\\n📊 Prediction Results:\")\n",
    "            print(f\"  • Random Forest Prediction: {rf_prediction:.2f}°C\")\n",
    "            print(f\"  • Gradient Boosting Prediction: {gb_prediction:.2f}°C\")\n",
    "            print(f\"  • Average Prediction: {(rf_prediction + gb_prediction) / 2:.2f}°C\")\n",
    "            \n",
    "            # Add some interpretative text\n",
    "            current_temp = X_pred['temperature_celsius'].values[0]\n",
    "            temp_diff = (rf_prediction + gb_prediction) / 2 - current_temp\n",
    "            \n",
    "            print(\"\\n🔮 Forecast Interpretation:\")\n",
    "            if abs(temp_diff) < 1:\n",
    "                print(\"  • Temperature expected to remain relatively stable\")\n",
    "            elif temp_diff > 0:\n",
    "                print(f\"  • Temperature expected to increase by approximately {temp_diff:.1f}°C\")\n",
    "            else:\n",
    "                print(f\"  • Temperature expected to decrease by approximately {abs(temp_diff):.1f}°C\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during prediction: {e}\")\n",
    "            print(\"Make sure the model has been trained properly.\")\n",
    "\n",
    "# Connect button click event to handler\n",
    "predict_button.on_click(on_predict_button_clicked)\n",
    "\n",
    "# Create the layout\n",
    "manual_inputs = widgets.VBox([temp_input, pressure_input, humidity_input, wind_input, month_input])\n",
    "manual_inputs_container = widgets.VBox([manual_inputs], layout=widgets.Layout(display='none'))\n",
    "\n",
    "def toggle_input_display(change):\n",
    "    if change['new'] == 'Enter manual data':\n",
    "        manual_inputs_container.layout.display = 'block'\n",
    "    else:\n",
    "        manual_inputs_container.layout.display = 'none'\n",
    "\n",
    "input_method.observe(toggle_input_display, names='value')\n",
    "\n",
    "# Final UI layout\n",
    "header = widgets.HTML(\"<h2>Weather Prediction Model Testing</h2>\")\n",
    "ui = widgets.VBox([\n",
    "    header,\n",
    "    widgets.HBox([location_dropdown]),\n",
    "    widgets.HBox([input_method]),\n",
    "    manual_inputs_container,\n",
    "    widgets.HBox([predict_button]),\n",
    "    widgets.HTML(\"<h3>Results:</h3>\"),\n",
    "    output_area\n",
    "])\n",
    "\n",
    "# Display the UI\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
